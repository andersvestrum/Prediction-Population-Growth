{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e949c622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data and building enriched feature set...\n",
      "Data loaded. Number of countries: 209\n",
      "\n",
      "\n",
      "Running 5-fold cross-validation for the stacked model...\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "got an unexpected keyword argument 'squared'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 290\u001b[39m\n\u001b[32m    288\u001b[39m eval_choice = \u001b[38;5;28minput\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDo you want to run a k-fold cross-validation evaluation now? (y/n): \u001b[39m\u001b[33m\"\u001b[39m).strip().lower()\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m eval_choice \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33my\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33myes\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m--> \u001b[39m\u001b[32m290\u001b[39m     \u001b[43mevaluate_model_cv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_enriched\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[38;5;66;03m# 3. Train the final stacked model on all countries\u001b[39;00m\n\u001b[32m    293\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining stacked model on all countries...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 211\u001b[39m, in \u001b[36mevaluate_model_cv\u001b[39m\u001b[34m(X, y, meta, n_splits)\u001b[39m\n\u001b[32m    208\u001b[39m model.fit(X_train, y_train)\n\u001b[32m    209\u001b[39m y_pred = model.predict(X_val)\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m rmse = \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    212\u001b[39m mae = mean_absolute_error(y_val, y_pred)\n\u001b[32m    213\u001b[39m r2 = r2_score(y_val, y_pred)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Library/CloudStorage/OneDrive-NTNU/Berkeley/2025Fall/Data Mining/project_final/Prediction-Population-Growth/venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:196\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    193\u001b[39m func_sig = signature(func)\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m params = \u001b[43mfunc_sig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    197\u001b[39m params.apply_defaults()\n\u001b[32m    199\u001b[39m \u001b[38;5;66;03m# ignore self/cls and positional/keyword markers\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.12-macos-aarch64-none/lib/python3.12/inspect.py:3280\u001b[39m, in \u001b[36mSignature.bind\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3275\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, /, *args, **kwargs):\n\u001b[32m   3276\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[32m   3277\u001b[39m \u001b[33;03m    and `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[32m   3278\u001b[39m \u001b[33;03m    if the passed arguments can not be bound.\u001b[39;00m\n\u001b[32m   3279\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3280\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.12-macos-aarch64-none/lib/python3.12/inspect.py:3269\u001b[39m, in \u001b[36mSignature._bind\u001b[39m\u001b[34m(self, args, kwargs, partial)\u001b[39m\n\u001b[32m   3259\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   3260\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mgot some positional-only arguments passed as \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   3261\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mkeyword arguments: \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[33m'\u001b[39m.format(\n\u001b[32m   (...)\u001b[39m\u001b[32m   3266\u001b[39m             ),\n\u001b[32m   3267\u001b[39m         )\n\u001b[32m   3268\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3269\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   3270\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mgot an unexpected keyword argument \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[33m'\u001b[39m.format(\n\u001b[32m   3271\u001b[39m                 arg=\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))))\n\u001b[32m   3273\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_arguments_cls(\u001b[38;5;28mself\u001b[39m, arguments)\n",
      "\u001b[31mTypeError\u001b[39m: got an unexpected keyword argument 'squared'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor, StackingRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "###############################################\n",
    "# Feature engineering: build enriched features\n",
    "###############################################\n",
    "def build_enriched_feature_set(pop_path = '../raw_data/world_population.csv', wb_path = '../raw_data/WorldBank.csv'):\n",
    "    \"\"\"\n",
    "    Load world population + World Bank data and build the enriched feature set\n",
    "    used in the main modeling script.\n",
    "\n",
    "    Returns:\n",
    "        X_enriched : DataFrame of features\n",
    "        y          : numpy array of log(2020 population)\n",
    "        meta       : DataFrame with identifiers (Country Name, CCA3, Region, IncomeGroup)\n",
    "        df         : DataFrame with raw merged data (includes 2020 Population)\n",
    "    \"\"\"\n",
    "    # Load the raw data\n",
    "    pop = pd.read_csv(pop_path)\n",
    "    wb = pd.read_csv(wb_path)\n",
    "\n",
    "    # Indicators we use from World Bank\n",
    "    indicator_cols = [\n",
    "        'Birth rate, crude (per 1,000 people)',\n",
    "        'Death rate, crude (per 1,000 people)',\n",
    "        'Electric power consumption (kWh per capita)',\n",
    "        'GDP (USD)',\n",
    "        'GDP per capita (USD)',\n",
    "        'Individuals using the Internet (% of population)',\n",
    "        'Infant mortality rate (per 1,000 live births)',\n",
    "        'Life expectancy at birth (years)',\n",
    "        'Population density (people per sq. km of land area)',\n",
    "        'Unemployment (% of total labor force) (modeled ILO estimate)'\n",
    "    ]\n",
    "\n",
    "    # Slice World Bank data for 2010 and 2000\n",
    "    wb_2010 = wb[wb['Year'] == 2010][['Country Code', 'Country Name', 'Region', 'IncomeGroup'] + indicator_cols].copy()\n",
    "    wb_2000 = wb[wb['Year'] == 2000][['Country Code'] + indicator_cols].copy()\n",
    "\n",
    "    # Rename 2000 columns so we can compute deltas\n",
    "    rename_cols = {col: col + ' 2000' for col in indicator_cols}\n",
    "    wb_2000 = wb_2000.rename(columns = rename_cols)\n",
    "\n",
    "    # Merge population data with 2010 indicators\n",
    "    df = pop.merge(\n",
    "        wb_2010,\n",
    "        left_on = 'CCA3',\n",
    "        right_on = 'Country Code',\n",
    "        how = 'inner'\n",
    "    )\n",
    "    # Merge 2000 indicators\n",
    "    df = df.merge(\n",
    "        wb_2000,\n",
    "        on = 'Country Code',\n",
    "        how = 'left'\n",
    "    )\n",
    "\n",
    "    # Reset index to keep everything aligned (0..n-1)\n",
    "    df = df.reset_index(drop = True)\n",
    "\n",
    "    # Target: log(2020 population)\n",
    "    y = np.log(df['2020 Population'].values)\n",
    "\n",
    "    # Baseline: log(2010 population) + region dummies\n",
    "    X_baseline = pd.DataFrame({\n",
    "        'log_pop_2010': np.log(df['2010 Population'].values)\n",
    "    })\n",
    "    X_baseline = pd.concat(\n",
    "        [X_baseline, pd.get_dummies(df['Region'], prefix = 'Region', drop_first = True)],\n",
    "        axis = 1\n",
    "    )\n",
    "\n",
    "    # Demo + econ features (levels in 2010)\n",
    "    X_demo = X_baseline.copy()\n",
    "    X_demo['birth_rate_2010'] = df['Birth rate, crude (per 1,000 people)']\n",
    "    X_demo['life_expectancy_2010'] = df['Life expectancy at birth (years)']\n",
    "    X_demo['log_gdp_pc_2010'] = np.log(df['GDP per capita (USD)'].replace(0, np.nan))\n",
    "    X_demo['log_density_2010'] = np.log(df['Population density (people per sq. km of land area)'].replace(0, np.nan))\n",
    "    X_demo = pd.concat(\n",
    "        [X_demo, pd.get_dummies(df['IncomeGroup'], prefix = 'Income', drop_first = True)],\n",
    "        axis = 1\n",
    "    )\n",
    "\n",
    "    # Enriched feature set: add trend and infrastructure variables\n",
    "    X_enriched = X_demo.copy()\n",
    "\n",
    "    # Growth in population 2000–2010\n",
    "    pop_2000 = df['2000 Population']\n",
    "    pop_2010 = df['2010 Population']\n",
    "    ratio = pop_2010 / pop_2000.replace(0, np.nan)\n",
    "    X_enriched['growth_00_10'] = ratio.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    # Changes in key indicators 2000–2010\n",
    "    X_enriched['delta_birth_rate_00_10'] = (\n",
    "        df['Birth rate, crude (per 1,000 people)'] -\n",
    "        df['Birth rate, crude (per 1,000 people) 2000']\n",
    "    )\n",
    "    X_enriched['delta_life_exp_00_10'] = (\n",
    "        df['Life expectancy at birth (years)'] -\n",
    "        df['Life expectancy at birth (years) 2000']\n",
    "    )\n",
    "    X_enriched['delta_gdp_pc_00_10'] = (\n",
    "        df['GDP per capita (USD)'] -\n",
    "        df['GDP per capita (USD) 2000']\n",
    "    )\n",
    "\n",
    "    # 2010 infrastructure / development variables\n",
    "    X_enriched['electricity_2010'] = df['Electric power consumption (kWh per capita)']\n",
    "    X_enriched['internet_2010'] = df['Individuals using the Internet (% of population)']\n",
    "    X_enriched['unemployment_2010'] = df['Unemployment (% of total labor force) (modeled ILO estimate)']\n",
    "\n",
    "    # Meta columns for later lookup and stratification\n",
    "    meta = df[['Country Name', 'CCA3', 'Region', 'IncomeGroup']].copy()\n",
    "\n",
    "    return X_enriched, y, meta, df\n",
    "\n",
    "\n",
    "###############################################\n",
    "# Define the final stacked model\n",
    "###############################################\n",
    "def build_final_model():\n",
    "    \"\"\"\n",
    "    Build the Stack_Lasso_RF model:\n",
    "    - Lasso + RandomForest as base learners\n",
    "    - Ridge as the meta-learner\n",
    "    \"\"\"\n",
    "    # Base learner 1: Lasso pipeline (impute + scale + Lasso)\n",
    "    lasso_pipe = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy = 'median')),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('reg', Lasso(alpha = 0.001, max_iter = 10000))\n",
    "    ])\n",
    "\n",
    "    # Base learner 2: Random Forest pipeline (impute + RF)\n",
    "    rf_pipe = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy = 'median')),\n",
    "        ('rf', RandomForestRegressor(\n",
    "            n_estimators = 500,\n",
    "            max_depth = None,\n",
    "            min_samples_leaf = 1,\n",
    "            max_features = 0.5,\n",
    "            random_state = 0,\n",
    "            n_jobs = -1\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    # Meta-learner on top: Ridge regression\n",
    "    final_reg = Ridge(alpha = 0.1)\n",
    "\n",
    "    # StackingRegressor that combines Lasso and RF\n",
    "    stack_model = StackingRegressor(\n",
    "        estimators = [\n",
    "            ('lasso', lasso_pipe),\n",
    "            ('rf', rf_pipe)\n",
    "        ],\n",
    "        final_estimator = final_reg,\n",
    "        n_jobs = -1\n",
    "    )\n",
    "\n",
    "    return stack_model\n",
    "\n",
    "\n",
    "###############################################\n",
    "# Cross-validation evaluation of the model\n",
    "###############################################\n",
    "def evaluate_model_cv(X, y, meta, n_splits = 5):\n",
    "    \"\"\"\n",
    "    Run k-fold cross-validation for the stacked model on the enriched feature set.\n",
    "\n",
    "    For each fold, we:\n",
    "      - build a fresh stacked model,\n",
    "      - train on the training folds,\n",
    "      - evaluate on the validation fold (RMSE, MAE, R2).\n",
    "\n",
    "    At the end, we print the mean and std of each metric across folds.\n",
    "    \"\"\"\n",
    "    strat_labels = meta['IncomeGroup'].fillna('Unknown').values\n",
    "\n",
    "    skf = StratifiedKFold(\n",
    "        n_splits = n_splits,\n",
    "        shuffle = True,\n",
    "        random_state = 0\n",
    "    )\n",
    "\n",
    "    rmse_list = []\n",
    "    mae_list = []\n",
    "    r2_list = []\n",
    "\n",
    "    print(f\"\\nRunning {n_splits}-fold cross-validation for the stacked model...\\n\")\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, strat_labels), start = 1):\n",
    "        # Build a fresh model for this fold\n",
    "        model = build_final_model()\n",
    "\n",
    "        X_train = X.iloc[train_idx]\n",
    "        y_train = y[train_idx]\n",
    "        X_val = X.iloc[val_idx]\n",
    "        y_val = y[val_idx]\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "\n",
    "        rmse = mean_squared_error(y_val, y_pred, squared = False)\n",
    "        mae = mean_absolute_error(y_val, y_pred)\n",
    "        r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "        rmse_list.append(rmse)\n",
    "        mae_list.append(mae)\n",
    "        r2_list.append(r2)\n",
    "\n",
    "        print(f\"Fold {fold}: RMSE = {rmse:.3f}, MAE = {mae:.3f}, R2 = {r2:.3f}\")\n",
    "\n",
    "    print(\"\\n=== Cross-validation summary ===\")\n",
    "    print(f\"RMSE: mean = {np.mean(rmse_list):.3f}, std = {np.std(rmse_list):.3f}\")\n",
    "    print(f\"MAE:  mean = {np.mean(mae_list):.3f}, std = {np.std(mae_list):.3f}\")\n",
    "    print(f\"R2:   mean = {np.mean(r2_list):.5f}, std = {np.std(r2_list):.5f}\")\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "###############################################\n",
    "# Helper: look up a country by name or CCA3 code\n",
    "###############################################\n",
    "def find_country_index(meta, query):\n",
    "    \"\"\"\n",
    "    Given a meta DataFrame and a user query, try to find the row index\n",
    "    of the matching country.\n",
    "\n",
    "    We first try:\n",
    "    - exact match on CCA3 code (case-insensitive)\n",
    "    - exact match on country name (case-insensitive, trimmed)\n",
    "\n",
    "    If that fails, we try a \"contains\" match on the country name\n",
    "    and return the first hit.\n",
    "\n",
    "    Returns:\n",
    "        idx (int) if found, or None if not found.\n",
    "    \"\"\"\n",
    "    if not query:\n",
    "        return None\n",
    "\n",
    "    q = query.strip()\n",
    "\n",
    "    # Try match by 3-letter country code (CCA3)\n",
    "    if len(q) == 3:\n",
    "        mask_code = meta['CCA3'].str.upper() == q.upper()\n",
    "        if mask_code.any():\n",
    "            return int(np.where(mask_code.values)[0][0])\n",
    "\n",
    "    # Try exact match on country name (case-insensitive)\n",
    "    name_series = meta['Country Name'].str.strip().str.lower()\n",
    "    mask_name = name_series == q.lower()\n",
    "    if mask_name.any():\n",
    "        return int(np.where(mask_name.values)[0][0])\n",
    "\n",
    "    # Try partial match on country name\n",
    "    contains_mask = name_series.str.contains(q.lower())\n",
    "    if contains_mask.any():\n",
    "        possible = meta[contains_mask]['Country Name'].tolist()\n",
    "        print(\"No exact match found. Found similar name(s):\")\n",
    "        for name in possible:\n",
    "            print(\"  -\", name)\n",
    "        # For simplicity, pick the first match\n",
    "        first_idx = int(np.where(contains_mask.values)[0][0])\n",
    "        print(\"Using:\", meta.iloc[first_idx]['Country Name'])\n",
    "        return first_idx\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "###############################################\n",
    "# Main: optional evaluation + interactive prediction\n",
    "###############################################\n",
    "if __name__ == '__main__':\n",
    "    # 1. Load data and build features\n",
    "    print(\"Loading data and building enriched feature set...\")\n",
    "    X_enriched, y, meta, df = build_enriched_feature_set()\n",
    "    print(f\"Data loaded. Number of countries: {X_enriched.shape[0]}\\n\")\n",
    "\n",
    "    # 2. Ask user if they want to run k-fold evaluation\n",
    "    eval_choice = input(\"Do you want to run a k-fold cross-validation evaluation now? (y/n): \").strip().lower()\n",
    "    if eval_choice in ['y', 'yes']:\n",
    "        evaluate_model_cv(X_enriched, y, meta, n_splits = 5)\n",
    "\n",
    "    # 3. Train the final stacked model on all countries\n",
    "    print(\"Training stacked model on all countries...\")\n",
    "    model = build_final_model()\n",
    "    model.fit(X_enriched, y)\n",
    "    print(\"Training complete.\\n\")\n",
    "\n",
    "    # 4. Interactive prediction loop\n",
    "    print(\"You can now query predictions for a country.\")\n",
    "    print(\"Type a country name (e.g., 'France') or 3-letter code (e.g., 'FRA').\")\n",
    "    print(\"Type 'q' or 'quit' to exit.\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"Enter country name or 3-letter code (q to quit): \").strip()\n",
    "        if user_input.lower() in ['q', 'quit', 'exit']:\n",
    "            print(\"Exiting.\")\n",
    "            break\n",
    "\n",
    "        idx = find_country_index(meta, user_input)\n",
    "        if idx is None:\n",
    "            print(\"Country not found. Please try again.\\n\")\n",
    "            continue\n",
    "\n",
    "        # Get single-row feature matrix for this country\n",
    "        X_row = X_enriched.iloc[[idx]]  # keep as DataFrame with one row\n",
    "\n",
    "        # Predict log population and convert back to level\n",
    "        log_pred = model.predict(X_row)[0]\n",
    "        pred_pop = float(np.exp(log_pred))\n",
    "\n",
    "        # Get actual population from df\n",
    "        actual_pop = float(df.iloc[idx]['2020 Population'])\n",
    "        country_name = meta.iloc[idx]['Country Name']\n",
    "        cca3 = meta.iloc[idx]['CCA3']\n",
    "\n",
    "        # Compute percentage error\n",
    "        if actual_pop > 0:\n",
    "            pct_error = 100.0 * (pred_pop - actual_pop) / actual_pop\n",
    "        else:\n",
    "            pct_error = np.nan\n",
    "\n",
    "        print(f\"\\nCountry: {country_name} ({cca3})\")\n",
    "        print(f\"Predicted 2020 population: {pred_pop:,.0f}\")\n",
    "        print(f\"Actual 2020 population:    {actual_pop:,.0f}\")\n",
    "        if not np.isnan(pct_error):\n",
    "            print(f\"Percentage error:          {pct_error:+.2f}%\")\n",
    "        print(\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
